{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Tiny GPT\n",
    "Build a small GPT model using PyTorch (in mac)"
   ],
   "id": "118228ff3fc9d889"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Check PyTorch instance",
   "id": "7553bb1b386d8737"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "_Notes:_\n",
    "\n",
    "**MPS (Metal Performance Shaders)**\n",
    "* Metal Performance Shaders is an Apple framework of highly optimized GPU shaders for image processing, linear algebra, and neural networks on top of Metal.\n",
    "* PyTorch, diffusers, and other ML libraries expose an mps device to offload tensor operations to the GPU via Metal/MPS on Apple silicon.\n"
   ],
   "id": "ca31039f830b58ed"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T20:13:54.583061Z",
     "start_time": "2025-12-26T20:13:54.563418Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "print(f\"Torch version: {torch.__version__} and MPS availability is: {torch.backends.mps.is_available()}\")\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Torch device: {device.type}\")\n",
    "\n",
    "torch.set_default_device(device)\n",
    "print(f\"Default device: {torch.get_default_device()}\")"
   ],
   "id": "394534f77af7eb6a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.7.0 and MPS availability is: True\n",
      "Torch device: mps\n",
      "Default device: mps:0\n"
     ]
    }
   ],
   "execution_count": 119
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Mathematical Explanation\n",
    "\n",
    "A LLM model only understands numbers - based on which it calculates the probability. The model selects the next one word that has got the highest probability.\n",
    "$$\n",
    "\\begin{aligned}\n",
    "P(w_1,w_2,w_3,......,w_n) = \\prod_{t=1}^{n}P(w_t|w_1,w_2,......,w_{t-1}) \\\\\n",
    "\\text{where, } w_i \\text{ represents a token}\n",
    "\\end{aligned}\n",
    "$$\n",
    "E.g., suppose,\n",
    "* we have the vocabulary (training set): [`very`, `tea`, `hot`, `is`, `the`]\n",
    "* the first 2 words fed to the model is: [`the`, `tea`]\n",
    "* the model will use the above formula of _Chain Probability_ to predict the next likely word.\n",
    "    * So, it will execute `P('is'|'the','tea')`. This reads as probability of `is` given the previous words are `the` and `tea`. Similarly it will execute `P('hot'|'the','tea')` and so on. The one with the highest probability wins.\n",
    "    * For a set of 4 tokens, the overall probability is calculated as\n",
    "$$\n",
    "\\begin{aligned}\n",
    "P(w_1,w_2,w_3,w_4) = P(w_1) \\times P(w_2|w_1) \\times P(w_3|w_1, w_2) \\times P(w_4|w_1, w_2, w_3)\n",
    "\\end{aligned}\n",
    "$$"
   ],
   "id": "10c93a036a6f2dd5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training Data",
   "id": "fbe378440a79427b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T20:13:54.592586Z",
     "start_time": "2025-12-26T20:13:54.583442Z"
    }
   },
   "cell_type": "code",
   "source": [
    "corpus = [\n",
    "    \"hello friends how are you\",\n",
    "    \"the tea is very hot\",\n",
    "    \"my name is Sushovan\",\n",
    "    \"the roads of Kolkata are busy\",\n",
    "    \"it is raining in Mumbai\",\n",
    "    \"the train is late again\",\n",
    "    \"i love eating samosas and drinking tea\",\n",
    "    \"holi is my favorite festival\",\n",
    "    \"diwali brings lights and sweets\",\n",
    "    \"india won the cricket match\"\n",
    "]"
   ],
   "id": "e6facecd2fbfcc27",
   "outputs": [],
   "execution_count": 120
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Tokenize Data for the model\n",
    "_Note_: Instead of using a tokenizer library (e.g. `BPE` - `Byte Pair Encoding` used in GPT or `SentencePiece` used in LLAMA), we shall be building a custom tokenizer to understand the concepts."
   ],
   "id": "eb7486fd996c3e50"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Put end marker and concatenate the corpus",
   "id": "2aaafa193bd04b4c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T20:13:54.623984Z",
     "start_time": "2025-12-26T20:13:54.595830Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text = \" \".join([s + \" <END>\" for s in corpus])\n",
    "print(text)"
   ],
   "id": "cef642771ea40b55",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello friends how are you <END> the tea is very hot <END> my name is Sushovan <END> the roads of Kolkata are busy <END> it is raining in Mumbai <END> the train is late again <END> i love eating samosas and drinking tea <END> holi is my favorite festival <END> diwali brings lights and sweets <END> india won the cricket match <END>\n"
     ]
    }
   ],
   "execution_count": 121
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Extract the words to build the vocabulary",
   "id": "8e9b4cfa3335d502"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T20:13:54.638364Z",
     "start_time": "2025-12-26T20:13:54.624476Z"
    }
   },
   "cell_type": "code",
   "source": [
    "words = list(set(text.split()))\n",
    "vocab_size = len(words)\n",
    "print(f\"Vocabulary: {words}\")\n",
    "print(f\"Vocabulary Size: {vocab_size}\")"
   ],
   "id": "aded0c62368a5545",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: ['very', 'name', 'and', 'diwali', 'hot', 'favorite', 'brings', 'my', 'samosas', 'again', 'holi', 'raining', 'how', 'i', 'roads', 'is', 'train', 'lights', 'drinking', 'the', 'sweets', 'tea', 'are', 'in', 'love', 'it', 'of', 'hello', 'you', 'match', 'cricket', 'won', 'busy', 'Sushovan', 'india', 'late', 'festival', 'Mumbai', '<END>', 'eating', 'Kolkata', 'friends']\n",
      "Vocabulary Size: 42\n"
     ]
    }
   ],
   "execution_count": 122
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Build the word index",
   "id": "6d3b521eee5a5043"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T20:13:54.654664Z",
     "start_time": "2025-12-26T20:13:54.641708Z"
    }
   },
   "cell_type": "code",
   "source": [
    "word2idx = {w: idx for idx, w in enumerate(words)}\n",
    "print(f\"Words to Index:  {word2idx}\")\n",
    "\n",
    "idx2word = {idx: w for w, idx in word2idx.items()}\n",
    "print(f\"Index to Words:  {idx2word}\")"
   ],
   "id": "fc89f08bb3def977",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words to Index:  {'very': 0, 'name': 1, 'and': 2, 'diwali': 3, 'hot': 4, 'favorite': 5, 'brings': 6, 'my': 7, 'samosas': 8, 'again': 9, 'holi': 10, 'raining': 11, 'how': 12, 'i': 13, 'roads': 14, 'is': 15, 'train': 16, 'lights': 17, 'drinking': 18, 'the': 19, 'sweets': 20, 'tea': 21, 'are': 22, 'in': 23, 'love': 24, 'it': 25, 'of': 26, 'hello': 27, 'you': 28, 'match': 29, 'cricket': 30, 'won': 31, 'busy': 32, 'Sushovan': 33, 'india': 34, 'late': 35, 'festival': 36, 'Mumbai': 37, '<END>': 38, 'eating': 39, 'Kolkata': 40, 'friends': 41}\n",
      "Index to Words:  {0: 'very', 1: 'name', 2: 'and', 3: 'diwali', 4: 'hot', 5: 'favorite', 6: 'brings', 7: 'my', 8: 'samosas', 9: 'again', 10: 'holi', 11: 'raining', 12: 'how', 13: 'i', 14: 'roads', 15: 'is', 16: 'train', 17: 'lights', 18: 'drinking', 19: 'the', 20: 'sweets', 21: 'tea', 22: 'are', 23: 'in', 24: 'love', 25: 'it', 26: 'of', 27: 'hello', 28: 'you', 29: 'match', 30: 'cricket', 31: 'won', 32: 'busy', 33: 'Sushovan', 34: 'india', 35: 'late', 36: 'festival', 37: 'Mumbai', 38: '<END>', 39: 'eating', 40: 'Kolkata', 41: 'friends'}\n"
     ]
    }
   ],
   "execution_count": 123
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Convert to tensor\n",
    "Replace each word in text with the corresponding index and fed that to a tensor"
   ],
   "id": "c1a24bd5e8ab22fd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T20:13:54.687426Z",
     "start_time": "2025-12-26T20:13:54.658972Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = torch.tensor([word2idx[idx] for idx in text.split()], dtype=torch.long)\n",
    "print(f\"Tensor Data: {data}\")\n",
    "print(f\"Data Shape: {data.shape}\")"
   ],
   "id": "741c1762e16eb58c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor Data: tensor([27, 41, 12, 22, 28, 38, 19, 21, 15,  0,  4, 38,  7,  1, 15, 33, 38, 19,\n",
      "        14, 26, 40, 22, 32, 38, 25, 15, 11, 23, 37, 38, 19, 16, 15, 35,  9, 38,\n",
      "        13, 24, 39,  8,  2, 18, 21, 38, 10, 15,  7,  5, 36, 38,  3,  6, 17,  2,\n",
      "        20, 38, 34, 31, 19, 30, 29, 38], device='mps:0')\n",
      "Data Shape: torch.Size([62])\n"
     ]
    }
   ],
   "execution_count": 124
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Define Parameters",
   "id": "f3789486939b1cd9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "`block_size`: also known as context_length. It means that how many previous words the llm would refer, to predict the next word",
   "id": "9e2f38b381cfa82d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T20:13:54.692246Z",
     "start_time": "2025-12-26T20:13:54.688569Z"
    }
   },
   "cell_type": "code",
   "source": "block_size = 6",
   "id": "6930b6cf3c17f0d2",
   "outputs": [],
   "execution_count": 125
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "`embedding_dim`: Embedding Dimension\n",
    "\n",
    "Each word in the tensor will be represented in the llm model as a dimensional vector of a defined size. Initially, random numbers are generate for each value in the dimensional vector. The llm uses this vector to predict the next word."
   ],
   "id": "2af64ee0e01255e4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T20:13:54.695338Z",
     "start_time": "2025-12-26T20:13:54.692527Z"
    }
   },
   "cell_type": "code",
   "source": "embedding_dim = 32",
   "id": "e1fe1f56717ab496",
   "outputs": [],
   "execution_count": 126
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T20:13:54.698824Z",
     "start_time": "2025-12-26T20:13:54.695532Z"
    }
   },
   "cell_type": "code",
   "source": "n_heads = 2  # number of Multi-head attention layer",
   "id": "7d6a4e2fc88c8127",
   "outputs": [],
   "execution_count": 127
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T20:13:54.701750Z",
     "start_time": "2025-12-26T20:13:54.699038Z"
    }
   },
   "cell_type": "code",
   "source": "n_layers = 2  # number of transformer blocks to use",
   "id": "7838f1ef6bf15d39",
   "outputs": [],
   "execution_count": 128
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T20:13:54.704329Z",
     "start_time": "2025-12-26T20:13:54.701944Z"
    }
   },
   "cell_type": "code",
   "source": "lr = 1e-3  # learning rate",
   "id": "b30677af88ba647",
   "outputs": [],
   "execution_count": 129
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T20:13:54.707406Z",
     "start_time": "2025-12-26T20:13:54.704542Z"
    }
   },
   "cell_type": "code",
   "source": "epochs = 1500  # number of training iterations",
   "id": "8334a7dd6a16bfdf",
   "outputs": [],
   "execution_count": 130
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Define batch function",
   "id": "58f566ce4f4acd80"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "`batch_size`: This indicates the number of sequences (or sentences) for the model to consider",
   "id": "2f472d6e55436eb4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T20:13:54.799416Z",
     "start_time": "2025-12-26T20:13:54.707735Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_batch(batch_size=16):\n",
    "    ix = torch.randint(len(data) - block_size, size=(batch_size,))  # 62 - 6 = 56 (0 to 55), 16\n",
    "    # the above function gives 16 examples of random sentences\n",
    "    x = torch.stack([data[i:i + block_size] for i in ix])\n",
    "    y = torch.stack([data[i + 1:i + block_size + 1] for i in ix])\n",
    "    return ix, x, y\n",
    "\n",
    "\n",
    "rand_int, input_batch, output_bath = get_batch()\n",
    "print(f\"Data: {data}\")\n",
    "print(f\"Batch Index: {rand_int}\")\n",
    "print(f\"input_batch shape: {input_batch.data}\")\n",
    "print(f\"output_bath shape: {output_bath.data}\")"
   ],
   "id": "d2de26d9a9041ca5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: tensor([27, 41, 12, 22, 28, 38, 19, 21, 15,  0,  4, 38,  7,  1, 15, 33, 38, 19,\n",
      "        14, 26, 40, 22, 32, 38, 25, 15, 11, 23, 37, 38, 19, 16, 15, 35,  9, 38,\n",
      "        13, 24, 39,  8,  2, 18, 21, 38, 10, 15,  7,  5, 36, 38,  3,  6, 17,  2,\n",
      "        20, 38, 34, 31, 19, 30, 29, 38], device='mps:0')\n",
      "Batch Index: tensor([11, 31, 38, 40,  9,  4,  7,  6, 31, 17, 21, 47, 10, 50, 44, 44],\n",
      "       device='mps:0')\n",
      "input_batch shape: tensor([[38,  7,  1, 15, 33, 38],\n",
      "        [16, 15, 35,  9, 38, 13],\n",
      "        [39,  8,  2, 18, 21, 38],\n",
      "        [ 2, 18, 21, 38, 10, 15],\n",
      "        [ 0,  4, 38,  7,  1, 15],\n",
      "        [28, 38, 19, 21, 15,  0],\n",
      "        [21, 15,  0,  4, 38,  7],\n",
      "        [19, 21, 15,  0,  4, 38],\n",
      "        [16, 15, 35,  9, 38, 13],\n",
      "        [19, 14, 26, 40, 22, 32],\n",
      "        [22, 32, 38, 25, 15, 11],\n",
      "        [ 5, 36, 38,  3,  6, 17],\n",
      "        [ 4, 38,  7,  1, 15, 33],\n",
      "        [ 3,  6, 17,  2, 20, 38],\n",
      "        [10, 15,  7,  5, 36, 38],\n",
      "        [10, 15,  7,  5, 36, 38]], device='mps:0')\n",
      "output_bath shape: tensor([[ 7,  1, 15, 33, 38, 19],\n",
      "        [15, 35,  9, 38, 13, 24],\n",
      "        [ 8,  2, 18, 21, 38, 10],\n",
      "        [18, 21, 38, 10, 15,  7],\n",
      "        [ 4, 38,  7,  1, 15, 33],\n",
      "        [38, 19, 21, 15,  0,  4],\n",
      "        [15,  0,  4, 38,  7,  1],\n",
      "        [21, 15,  0,  4, 38,  7],\n",
      "        [15, 35,  9, 38, 13, 24],\n",
      "        [14, 26, 40, 22, 32, 38],\n",
      "        [32, 38, 25, 15, 11, 23],\n",
      "        [36, 38,  3,  6, 17,  2],\n",
      "        [38,  7,  1, 15, 33, 38],\n",
      "        [ 6, 17,  2, 20, 38, 34],\n",
      "        [15,  7,  5, 36, 38,  3],\n",
      "        [15,  7,  5, 36, 38,  3]], device='mps:0')\n"
     ]
    }
   ],
   "execution_count": 131
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T20:16:39.888229Z",
     "start_time": "2025-12-26T20:16:39.794202Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "print(f\"Decoded data: \\n{[idx2word[i.item()] for i in data]}\")\n",
    "print(f\"input stack words: \\n{np.array([[idx2word[i.item()] for i in b] for b in input_batch])}\")\n",
    "print(f\"output stack words: \\n{np.array([[idx2word[i.item()] for i in b] for b in output_bath])}\")"
   ],
   "id": "b02413e3c14c4be9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded data: \n",
      "['hello', 'friends', 'how', 'are', 'you', '<END>', 'the', 'tea', 'is', 'very', 'hot', '<END>', 'my', 'name', 'is', 'Sushovan', '<END>', 'the', 'roads', 'of', 'Kolkata', 'are', 'busy', '<END>', 'it', 'is', 'raining', 'in', 'Mumbai', '<END>', 'the', 'train', 'is', 'late', 'again', '<END>', 'i', 'love', 'eating', 'samosas', 'and', 'drinking', 'tea', '<END>', 'holi', 'is', 'my', 'favorite', 'festival', '<END>', 'diwali', 'brings', 'lights', 'and', 'sweets', '<END>', 'india', 'won', 'the', 'cricket', 'match', '<END>']\n",
      "input stack words: \n",
      "[['<END>' 'my' 'name' 'is' 'Sushovan' '<END>']\n",
      " ['train' 'is' 'late' 'again' '<END>' 'i']\n",
      " ['eating' 'samosas' 'and' 'drinking' 'tea' '<END>']\n",
      " ['and' 'drinking' 'tea' '<END>' 'holi' 'is']\n",
      " ['very' 'hot' '<END>' 'my' 'name' 'is']\n",
      " ['you' '<END>' 'the' 'tea' 'is' 'very']\n",
      " ['tea' 'is' 'very' 'hot' '<END>' 'my']\n",
      " ['the' 'tea' 'is' 'very' 'hot' '<END>']\n",
      " ['train' 'is' 'late' 'again' '<END>' 'i']\n",
      " ['the' 'roads' 'of' 'Kolkata' 'are' 'busy']\n",
      " ['are' 'busy' '<END>' 'it' 'is' 'raining']\n",
      " ['favorite' 'festival' '<END>' 'diwali' 'brings' 'lights']\n",
      " ['hot' '<END>' 'my' 'name' 'is' 'Sushovan']\n",
      " ['diwali' 'brings' 'lights' 'and' 'sweets' '<END>']\n",
      " ['holi' 'is' 'my' 'favorite' 'festival' '<END>']\n",
      " ['holi' 'is' 'my' 'favorite' 'festival' '<END>']]\n",
      "output stack words: \n",
      "[['my' 'name' 'is' 'Sushovan' '<END>' 'the']\n",
      " ['is' 'late' 'again' '<END>' 'i' 'love']\n",
      " ['samosas' 'and' 'drinking' 'tea' '<END>' 'holi']\n",
      " ['drinking' 'tea' '<END>' 'holi' 'is' 'my']\n",
      " ['hot' '<END>' 'my' 'name' 'is' 'Sushovan']\n",
      " ['<END>' 'the' 'tea' 'is' 'very' 'hot']\n",
      " ['is' 'very' 'hot' '<END>' 'my' 'name']\n",
      " ['tea' 'is' 'very' 'hot' '<END>' 'my']\n",
      " ['is' 'late' 'again' '<END>' 'i' 'love']\n",
      " ['roads' 'of' 'Kolkata' 'are' 'busy' '<END>']\n",
      " ['busy' '<END>' 'it' 'is' 'raining' 'in']\n",
      " ['festival' '<END>' 'diwali' 'brings' 'lights' 'and']\n",
      " ['<END>' 'my' 'name' 'is' 'Sushovan' '<END>']\n",
      " ['brings' 'lights' 'and' 'sweets' '<END>' 'india']\n",
      " ['is' 'my' 'favorite' 'festival' '<END>' 'diwali']\n",
      " ['is' 'my' 'favorite' 'festival' '<END>' 'diwali']]\n"
     ]
    }
   ],
   "execution_count": 133
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
